{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdefc79",
   "metadata": {},
   "source": [
    "# Shannon_Demon\n",
    "Backtests various versions of Shannns Demon strategy. Demon strategy is to rebalance frequently between cash and a stock.\n",
    "This program can backtest many versions of the strategy.\n",
    "\n",
    "Started 04/20/23\n",
    "Last edit 05/03/23 - RebalDemon works.\n",
    "\n",
    "User controls - Create ControlPanel.xlsx to contain all contral data.\n",
    "1. Stock ticker list. Shannon_Demon will invest these stocks. Cash is total cash for ALL the stocks, plus cash acct. \n",
    "2. Invest freq. (Daily. Weekly, Monthly, Quarterly, Annual). Maybe set as # trading days. \n",
    "3. Plot results.\n",
    "4. Calculate ARR, max. drawdown, max. neg duration, and Sharpe ratio for this long-only strategy.\n",
    "\n",
    "Files\n",
    "1. price history - permanent file. It saves the EOD prices for each ticker and adds to the file. When tickers are chenged, SD checks this file and gets only the prices missing from the price_history file.\n",
    "2. run results - SD records actual run results for each scenario in a separate file. \n",
    "3. run_log - a log of all runs, with file ID, run date, tickers, cash, and stats for the run.\n",
    "\n",
    "Complete Process\n",
    "1. Read specs for this run from an xlsx file \"Gears.xlsx\".\n",
    "2. Check price_history file to see which prices are needed\n",
    "3. Get those prices from DARqube.\n",
    "4. Set up the results dataframe.\n",
    "5. Run the backtest.\n",
    "6. Calculate the stats for the run.\n",
    "7. Update the run_log.\n",
    "8. Plot the results.\n",
    "\n",
    "Development Steps\n",
    "1. Write backtester.\n",
    "  a. Write pricegrabber.\n",
    "  b. Write backtester.\n",
    "  c. Write Scorekeeper\n",
    "  d. Save results.\n",
    "2. Write run_logger.\n",
    "3. Write DataSaver.\n",
    "\n",
    "\n",
    "# TODO\n",
    "Developer ToDo list 05/03/23.\n",
    "1. Write fct Rebal_Data, which finds EOW, EOM, EOQ and EOY trade records with the stock prices for rebal runs. \n",
    "2. Write Scorekeeper fct.\n",
    "3. Write Data_Logger and Run_Logger\n",
    "4. Consider plotting Port_val a d Stock_Val for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1577b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********\n",
    "#\n",
    "#Shannon_Demon - created 04/21/23\n",
    "#    Goal - Test versions of shannon's Demon and compare performance stats.\n",
    "#     Steps\n",
    "#          1. Initialize libraries, constants, etc.\n",
    "#          2. Get prices for selected tickers from DARqube.\n",
    "#          3. Calculate turning  ponts price_change delta for date D from date D - MAX_SPIKE DAYS\n",
    "#\n",
    "# **********\n",
    "\n",
    "# **********\n",
    "#\n",
    "# User sets constants\n",
    "#\n",
    "# **********\n",
    "\n",
    "# Set DAR_key\n",
    "DAR_key = '90180f15ecc74513a01ca017eca2bb4f'\n",
    "TICKERS = ('DDOG', 'SNOW', 'CRWD') #, 'FSLY', 'OKTA', 'NWBO', 'SANA', 'ONCS', 'BBAI')\n",
    "\n",
    "# Set minimum pivot point size as a percent. Adjust this to produce a chart where each zigzag takes 5-25 trading days.\n",
    "PIVOT_POINT_PCT = .05\n",
    "\n",
    "# Set DAYS_BACK as an integer number of days back from yesterday.\n",
    "DAYS_BACK = 90 # approx. 1 year. Note DAYS_BACK uses calendar days, not trading days. \n",
    "\n",
    "# **********\n",
    "#\n",
    "# Import LIbraries\n",
    "#\n",
    "# **********\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib.pyplot import plot, scatter\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests   # for http requests\n",
    "import scipy\n",
    "from   scipy import stats\n",
    "from   scipy.stats import norm\n",
    "import stock_indicators\n",
    "from   stock_indicators import indicators, EndType\n",
    "from   stock_indicators.indicators.common.enums import EndType\n",
    "\n",
    "import time\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2699fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the zigzag functions.\n"
     ]
    }
   ],
   "source": [
    "# **********\n",
    "#\n",
    "#ZigZagPlotter - functions that cal the ZigZag pivot points.\n",
    "#\n",
    "# **********\n",
    "\n",
    "def pct_change(X):\n",
    "    data_pct_change = diff(X, 1, None) / shift(X,1, None) \n",
    "    return data_pct_change\n",
    "\n",
    "def shift(arr, num, fill_value=np.nan):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = fill_value\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = fill_value\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result[:] = arr\n",
    "    return result\n",
    "\n",
    "def diff(arr, num, fill_value=np.nan):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = fill_value\n",
    "        result[num:] = arr[num:] - arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = fill_value\n",
    "        result[:num] = arr[:num] - arr[-num:]\n",
    "    else:\n",
    "        result[:] = arr\n",
    "    return result\n",
    "\n",
    "def calczigzag(X, pc, include_first):\n",
    "\n",
    "    data_pct_change = pct_change(X)\n",
    "    pct_change_mask = np.sign(data_pct_change)\n",
    "    pct_change_mask_abs_diff = np.abs(diff(pct_change_mask,1,np.nan))\n",
    "    split_mask = np.where(pct_change_mask_abs_diff == 2)[0] - 1\n",
    "    \n",
    "    data_split_pct_change = pct_change(X[split_mask])\n",
    "\n",
    "    data_split_pct_change_filtered_indices = np.where(np.abs(data_split_pct_change) > pc)\n",
    "    data_split_pct_change_filtered = data_split_pct_change[data_split_pct_change_filtered_indices]\n",
    "    pivot_indices = split_mask[data_split_pct_change_filtered_indices]\n",
    "    pivot_indices_filtered = pivot_indices[diff(np.sign(data_split_pct_change_filtered),-1,None)!= 0]\n",
    "    if include_first:\n",
    "        pivot_indices_filtered = np.concatenate(([0],pivot_indices_filtered))\n",
    "        \n",
    "    return pivot_indices_filtered\n",
    "\n",
    "def zigzag(X, pc, include_first = True):\n",
    "    '''\n",
    "    X: numpy.ndarray/list/pandas.core.series.Series\n",
    "        Data\n",
    "    pc: float\n",
    "        Precision level\n",
    "    include_first: bool\n",
    "        Boolean indicating whether to include the first observation as a pivot point\n",
    "    '''\n",
    "\n",
    "    if type(X) is np.ndarray:\n",
    "        pivot_indices = calczigzag(X, pc, include_first)\n",
    "        return pivot_indices\n",
    "\n",
    "    elif type(X) is pd.Series:\n",
    "        X_np = X.values \n",
    "        X_index = X.index\n",
    "        pivot_indices = calczigzag(X_np, pc, include_first)\n",
    "        return X_index[pivot_indices]\n",
    "\n",
    "    elif type(X) is list:\n",
    "        X_np = np.array(X)\n",
    "        pivot_indices = calczigzag(X_np, pc, include_first)\n",
    "        return pivot_indices\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"X should be pd.series, np.array or list\")\n",
    " \n",
    "def PlotPivots(ticker_prices):\n",
    "    X = ticker_prices['adjusted_close']\n",
    "    zz_pivots = zigzag(X,PIVOT_POINT_PCT, False)\n",
    "    \n",
    "    print('for ', ticker)\n",
    "    plot(X, '--')\n",
    "    plot(zz_pivots, X[zz_pivots])\n",
    "    scatter(zz_pivots, X[zz_pivots])\n",
    "    #plt.figure(figsize = (10, 4.8))\n",
    "    #plt.xticks(rotation = 90)\n",
    "    #display(plt.plot(x,y))\n",
    "    plt.show()\n",
    "    print(ticker, ' plot done.')\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "print('Loaded the zigzag functions.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51afdda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started reading the DemonLib01 functions, but not yet in a lib.\n",
      "loaded Demon functions.\n"
     ]
    }
   ],
   "source": [
    "# **********\n",
    "#\n",
    "# Demon Functions\n",
    "# GetRebalDates\n",
    "# GetStockPrices\n",
    "# Backtester - runs backtests with various configs.It calls PortTrader to execute all actual trades.\n",
    "# PortTrader - Recommends trades according to Demon rules and logs results for tracking. Calculates performance.\n",
    "# DemonPlot - plots performance for the selected run.\n",
    "# DemonLogger - logs all the results.\n",
    "#\n",
    "# **********\n",
    "print('started reading the DemonLib01 functions, but not yet in a lib.')\n",
    "\n",
    "# **********\n",
    "#\n",
    "# GetRebalDates\n",
    "# Returns a df with ticker prices and dates for rebal dates only.\n",
    "# 1. Read rebal_dates.csv, which contains the complete set of trade dates and rebal dates so far. \n",
    "# 2. Check backtest date range to see if more trade dates needed. If so, call Darqube to fill the date range.\n",
    "# 2. If rebal_dates.csv does not exist, then get dates starting 01/01/2000 and calculate all rebal dates.\n",
    "# 3. Rebal dates are EOW, EOM, EOQ, and EOY. rebal_dates_df has corresponding cols. It is a sparse df.\n",
    "# 4. \n",
    "# ONlY rebal_freq = 'Daily' is implemented so far\n",
    "# Start_date and end_date functions not implemented yet.\n",
    "# **********\n",
    "def GetRebalData(stock_prices, start_date, end_date, rebal_freq):\n",
    "    if rebal_freq == 'Daily':\n",
    "        rebal_prices = stock_prices.copy() #rebal_prices has a record and prices for only rebal days.\n",
    "    elif rebal_freq == 'EOW':\n",
    "        # Select all friday records, or last trading day of each week. \n",
    "        pass\n",
    "    elif rebal_freq == 'EOM':\n",
    "        # selest last trading day of each month\n",
    "        pass\n",
    "    elif rebal_freq == 'EOQ':\n",
    "        # select last trading day of the quarter\n",
    "        pass\n",
    "    elif rebal_freq == 'EOY':\n",
    "        # select last trading day of the year.\n",
    "        pass\n",
    "\n",
    "    #run_report['rebal_dates'] = rebal_dates[rebal_freq] # this col is True where date is rebal (EOW, EOM, EOQ, EOY).\n",
    "    #run_report = run_report[run_report['rebal_dates'] == True].copy()\n",
    "\n",
    "    return rebal_prices\n",
    "\n",
    "# **********\n",
    "#\n",
    "# GetStockPrices\n",
    "# 1. Check demon_stock_prices file  to see if new tickers or new date range. If so, get needed stock prices from Darqube.\n",
    "# 2. write the updated file demon_stock_prices.csv. Note this is a persistent data file. \n",
    "#\n",
    "# **********\n",
    "def GetStockPrices(start_date, end_date, tickers, DAR_key):\n",
    "    all_ticker_prices = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "    \n",
    "        ticker_df = pd.DataFrame()\n",
    "        price_rqst = 'https://api.darqube.com/data-api/market_data/historical/' + ticker + '?token=' + DAR_key + \\\n",
    "                     '&start_date=' + start_date_str + '&end_date=' + end_date_str + '&interval=1d'\n",
    "    \n",
    "        #price_rqst = 'https://api.darqube.com/data-api/market_data/quote/' + ticker + '?token=' + DAR_key\n",
    "        response = requests.get(price_rqst)\n",
    "        price_dict = response.json()\n",
    "        ticker_prices = pd.DataFrame(data = price_dict)\n",
    "\n",
    "        drop_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        ticker_prices.drop(columns = drop_cols, inplace = True)\n",
    "        price_col = ticker + '_Price'\n",
    "        rename_cols = {'adjusted_close': price_col}\n",
    "        ticker_prices.rename(columns = rename_cols, inplace = True)\n",
    "    \n",
    "        try:\n",
    "            all_ticker_prices = pd.merge(all_ticker_prices, ticker_prices, how='outer', left_index=True, right_index = True)\n",
    "        except IndexError:\n",
    "            all_ticker_prices = all_ticker_prices if not all_ticker_prices.empty else ticker_prices\n",
    "\n",
    "    all_ticker_prices['date'] = pd.to_datetime(ticker_prices['time'], unit = 's')\n",
    "    all_ticker_prices['date_str'] = all_ticker_prices['date'].dt.strftime('%Y-%m-%d')\n",
    "    all_ticker_prices.set_index('date', inplace = True)\n",
    "         \n",
    "    print(all_ticker_prices)\n",
    "    return all_ticker_prices\n",
    "    \n",
    "    stop\n",
    "\n",
    "\n",
    "\n",
    "# **********\n",
    "#\n",
    "# RebalDemon - From inuts, RebalDemon builds a file which contains EOD prices for every rebal date\n",
    "#              for every ticker in tickers. the rebal_prices df has no empty rows. \n",
    "# 1. Set up portfolio df.\n",
    "# 2. For each rebal date, get prices and rebalance each stock holding. \n",
    "# 3. Read rebal_date.csv, which contains the complete set of trade dates and rebal dates so far. \n",
    "# 2. Check backtest date range to see if more trade dates needed. If so, call Darqube to fill the date range.\n",
    "# 2. If rebal_dates.csv does not exist, then get dates starting 01/01/2000 and calculate all rebal dates.\n",
    "# 3. Rebal dates are EOW, EOM, EOQ, and EOY. rebal_dates_df has corresponding cols. It is a sparse df.\n",
    "#\n",
    "# Demon Logic - Must use shift method for columns to find daily price change.\n",
    "# 1. Set all new cols = 0.0\n",
    "# 2. Shift stock price (fill_value = stock_price.loc[0])\n",
    "# 3. Calculate all row 0 vlaues.\n",
    "# 4. Calculate stock price delta. \n",
    "# 5. Calculate rebal_val in its own loop, for each stock. Here you must use .loc[x+1] and .loc[x]. Start loop at 1.\n",
    "# 6. Cash = start_cash + rebal cumsum.\n",
    "# 7. Calculate other cols w/vector ops.\n",
    "# **********\n",
    "\n",
    "def RebalDemon(rebal_prices, tickers, start_date_str, end_date_str, start_cash):\n",
    "    #TODO - Consider\n",
    "    # Note both rebal_dates and ticker_prices MUST use the price date as the index. \n",
    "    # Select ticker prices that match the rebal dates. Note this assumes you buy at the EOD price, not next morning!\n",
    "    # Can code the buy either way, but muist konw the BOD price for the next day.\n",
    "\n",
    "    run_report = rebal_prices.copy()\n",
    "    \n",
    "    # Initialize column names and initial values for run_report.\n",
    "    \n",
    "    print('ticker count = ', len(tickers))\n",
    "    cash_per_tick = start_cash / len(tickers) / 2.0 # 50% to stock, 50% to cash\n",
    "    print('cash per ticker = ', cash_per_tick)\n",
    "    \n",
    "    for tick in tickers:\n",
    "        tick_price  = tick + '_Price'\n",
    "        tick_shares = tick + '_Shares'\n",
    "        tick_value  = tick + '_Value'\n",
    "        tick_cash   = tick + '_Cash'  # Note tick_cash = tick_value after rebal, so one is redundant.\n",
    "        tick_price_change = tick + '_Price_Chg'\n",
    "        tick_rebal_val    = tick + '_Rebal_Val'\n",
    "        \n",
    "        # Initialize all calculated ticker column values to zero.\n",
    "\n",
    "        run_report[tick_shares]       = 0.0\n",
    "        run_report[tick_value]        = 0.0\n",
    "        run_report[tick_price_change] = 0.0\n",
    "        run_report[tick_rebal_val]    = 0.0\n",
    "        # Note we do not clculate tick_cash, since it is rebalanced every time to equal tick_value\n",
    "        # Initialize all values in the first row to a balanced port. 50% stock, 50% cash\n",
    "        \n",
    "        run_report.loc[0, tick_value] = cash_per_tick\n",
    "        run_report.loc[0, tick_shares]= cash_per_tick / run_report.loc[0, tick_price]\n",
    "       \n",
    "        # Initialize first row of all columns with a time offset to correct value. NaN won't work.\n",
    "        # Columns for 'prev_price' and 'tick_rebal_val' are reused for each ticker. \n",
    "        \n",
    "        run_report['prev_Price'] = run_report[tick_price].shift(periods = 1, fill_value = run_report.loc[0, tick_price])\n",
    "        run_report[tick_price_change] = run_report[tick_price] - run_report['prev_Price']\n",
    "        \n",
    "        print('before rebal loop...')\n",
    "        print(run_report)\n",
    "        \n",
    "        for i in range(run_report.shape[0]-1):  #This loop sequences through each row in order to do the rebalance.\n",
    "            run_report.loc[i+1, tick_rebal_val] = run_report.loc[i+1, tick_price_change] * run_report.loc[i,tick_shares] / 2.0\n",
    "            run_report.loc[i+1, tick_value]  = run_report.loc[i+1, tick_rebal_val] + run_report.loc[i, tick_value]\n",
    "            run_report.loc[i+1, tick_shares] = run_report.loc[i+1, tick_value] / run_report.loc[i+1, tick_price]\n",
    "            \n",
    "        print('after rebal loop')\n",
    "        print(run_report)      \n",
    "        \n",
    "    # Calculate cash, share,  and port values with vector and numpy ops.\n",
    "    share_val_cols = []\n",
    "    for tick in tickers:\n",
    "        tick_value  = tick + '_Value'\n",
    "        share_val_cols.append(tick_value)\n",
    "    run_report['Share_Val'] = np.sum(run_report[share_val_cols], axis=1)\n",
    "    run_report['Cash_Val'] = run_report['Share_Val'].copy()\n",
    "    run_report['Port_Val'] = run_report['Share_Val'] * 2.0\n",
    "            \n",
    "    return run_report\n",
    "        \n",
    "# **********\n",
    "# 05/03/23 - Status - Written, not yet tested. Need test file.\n",
    "# Scorekeeper generates performance stats for each run_report.\n",
    "# 1. Set up run_results df.\n",
    "# 2. Calculate each metric: Sharpe Ratio, max drawdown, MAR (=CAGR / MDD), another risk measurement.. \n",
    "#      Others? Up capture, down capture (compare to daily?), CAGR, tot. return\n",
    "# 4. Pick a comparison index for Sharpe Ratio.\n",
    "# 5. To calc MDD < use pd.cumsum\n",
    "# **********\n",
    "\n",
    "def Scorekeeper(report):\n",
    "    # Calc max drawdown and max duration.\n",
    "    # 1. Find peaks.\n",
    "    peak = 0.0\n",
    "    prev_peak_index = 0\n",
    "    report['Peaks'] = False\n",
    "    report['Duration'] = 0\n",
    "    report['Drawdown'] = 0\n",
    "    for i in range(report.shape[0]):\n",
    "        port_val = report.loc[i, 'Port_Val']\n",
    "        if port_val > peak:\n",
    "            if report.loc[i, 'Duration'] == 0:\n",
    "                report.loc[i, 'Duration'] = i - prev_peak_index\n",
    "                # Get max drawdown for this range.\n",
    "                dd_index_range = [prev_peak_index, i]\n",
    "                port_values = report[index_range, 'Port_val'].values\n",
    "                report.loc[i, 'Drawdown'] = port_values.min() - peak\n",
    "                peak = port_val\n",
    "                prev_peak_index = i\n",
    "    Get max_drawdown and max_duration\n",
    "    max_drawdown = report['Drawdown'].min()\n",
    "    max_duration = report['Duration'].min()\n",
    "    \n",
    "    # Calc CAGR\n",
    "    CAGR = (report.loc[-1, 'Port_Val'] / report.loc[0, 'Port_Val'])**(1/years) - 1) * 100.0\n",
    "    MAR  = CAGR / max_drawdown\n",
    "    #Sharpe = (RPort - RBenchmark) / Std. Dev Port\n",
    "    \n",
    "print('loaded Demon functions.')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7053dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODAY =  2023-05-03 16:51:08.340126\n",
      "end_date =  2023-05-02 16:51:08.340126\n",
      "end_date_str =  2023-05-02\n",
      "start_date_str =  2023-04-23\n",
      "when RUN_TYPE = tet, all_ticker_prices = \n",
      "        date  XOM_Price  AMZN_Price        time   date_str\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023\n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023\n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023\n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023\n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023\n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023\n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023\n",
      "from all_ticker_prices, first date =  4/20/2023\n",
      "from all_ticker_prices, last date =  4/28/2023\n",
      "Read all_ticker_prices.csv\n",
      "GetRebalData just ran.\n",
      "ticker count =  2\n",
      "cash per ticker =  250.0\n",
      "before rebal loop...\n",
      "        date  XOM_Price  AMZN_Price        time   date_str  XOM_Shares  \\\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023         2.5   \n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023         0.0   \n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023         0.0   \n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023         0.0   \n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023         0.0   \n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023         0.0   \n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023         0.0   \n",
      "\n",
      "   XOM_Value  XOM_Price_Chg  XOM_Rebal_Val  prev_Price  \n",
      "0      250.0              0            0.0         100  \n",
      "1        0.0              1            0.0         100  \n",
      "2        0.0              4            0.0         101  \n",
      "3        0.0              5            0.0         105  \n",
      "4        0.0             -2            0.0         110  \n",
      "5        0.0             -1            0.0         108  \n",
      "6        0.0              3            0.0         107  \n",
      "after rebal loop\n",
      "        date  XOM_Price  AMZN_Price        time   date_str  XOM_Shares  \\\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023    2.500000   \n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023    2.487624   \n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023    2.440240   \n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023    2.384780   \n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023    2.406862   \n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023    2.418109   \n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023    2.385135   \n",
      "\n",
      "    XOM_Value  XOM_Price_Chg  XOM_Rebal_Val  prev_Price  \n",
      "0  250.000000              0       0.000000         100  \n",
      "1  251.250000              1       1.250000         100  \n",
      "2  256.225248              4       4.975248         101  \n",
      "3  262.325849              5       6.100601         105  \n",
      "4  259.941068             -2      -2.384780         110  \n",
      "5  258.737637             -1      -1.203431         108  \n",
      "6  262.364800              3       3.627163         107  \n",
      "before rebal loop...\n",
      "        date  XOM_Price  AMZN_Price        time   date_str  XOM_Shares  \\\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023    2.500000   \n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023    2.487624   \n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023    2.440240   \n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023    2.384780   \n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023    2.406862   \n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023    2.418109   \n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023    2.385135   \n",
      "\n",
      "    XOM_Value  XOM_Price_Chg  XOM_Rebal_Val  prev_Price  AMZN_Shares  \\\n",
      "0  250.000000              0       0.000000      103.81     2.408246   \n",
      "1  251.250000              1       1.250000      103.81     0.000000   \n",
      "2  256.225248              4       4.975248      106.96     0.000000   \n",
      "3  262.325849              5       6.100601      106.21     0.000000   \n",
      "4  259.941068             -2      -2.384780      102.57     0.000000   \n",
      "5  258.737637             -1      -1.203431      104.98     0.000000   \n",
      "6  262.364800              3       3.627163      109.82     0.000000   \n",
      "\n",
      "   AMZN_Value  AMZN_Price_Chg  AMZN_Rebal_Val  \n",
      "0       250.0            0.00             0.0  \n",
      "1         0.0            3.15             0.0  \n",
      "2         0.0           -0.75             0.0  \n",
      "3         0.0           -3.64             0.0  \n",
      "4         0.0            2.41             0.0  \n",
      "5         0.0            4.84             0.0  \n",
      "6         0.0           -4.37             0.0  \n",
      "after rebal loop\n",
      "        date  XOM_Price  AMZN_Price        time   date_str  XOM_Shares  \\\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023    2.500000   \n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023    2.487624   \n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023    2.440240   \n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023    2.384780   \n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023    2.406862   \n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023    2.418109   \n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023    2.385135   \n",
      "\n",
      "    XOM_Value  XOM_Price_Chg  XOM_Rebal_Val  prev_Price  AMZN_Shares  \\\n",
      "0  250.000000              0       0.000000      103.81     2.408246   \n",
      "1  251.250000              1       1.250000      103.81     2.372784   \n",
      "2  256.225248              4       4.975248      106.96     2.381162   \n",
      "3  262.325849              5       6.100601      106.21     2.423413   \n",
      "4  259.941068             -2      -2.384780      102.57     2.395596   \n",
      "5  258.737637             -1      -1.203431      104.98     2.342807   \n",
      "6  262.364800              3       3.627163      109.82     2.391351   \n",
      "\n",
      "   AMZN_Value  AMZN_Price_Chg  AMZN_Rebal_Val  \n",
      "0  250.000000            0.00        0.000000  \n",
      "1  253.792987            3.15        3.792987  \n",
      "2  252.903193           -0.75       -0.889794  \n",
      "3  248.569479           -3.64       -4.333714  \n",
      "4  251.489691            2.41        2.920213  \n",
      "5  257.287034            4.84        5.797343  \n",
      "6  252.168002           -4.37       -5.119033  \n",
      "Wow, RebalDemon just ran.\n",
      "        date  XOM_Price  AMZN_Price        time   date_str  XOM_Shares  \\\n",
      "0  4/20/2023        100      103.81  1681948800  4/20/2023    2.500000   \n",
      "1  4/21/2023        101      106.96  1682035200  4/21/2023    2.487624   \n",
      "2  4/24/2023        105      106.21  1682294400  4/24/2023    2.440240   \n",
      "3  4/25/2023        110      102.57  1682380800  4/25/2023    2.384780   \n",
      "4  4/26/2023        108      104.98  1682467200  4/26/2023    2.406862   \n",
      "5  4/27/2023        107      109.82  1682553600  4/27/2023    2.418109   \n",
      "6  4/28/2023        110      105.45  1682640000  4/28/2023    2.385135   \n",
      "\n",
      "    XOM_Value  XOM_Price_Chg  XOM_Rebal_Val  prev_Price  AMZN_Shares  \\\n",
      "0  250.000000              0       0.000000      103.81     2.408246   \n",
      "1  251.250000              1       1.250000      103.81     2.372784   \n",
      "2  256.225248              4       4.975248      106.96     2.381162   \n",
      "3  262.325849              5       6.100601      106.21     2.423413   \n",
      "4  259.941068             -2      -2.384780      102.57     2.395596   \n",
      "5  258.737637             -1      -1.203431      104.98     2.342807   \n",
      "6  262.364800              3       3.627163      109.82     2.391351   \n",
      "\n",
      "   AMZN_Value  AMZN_Price_Chg  AMZN_Rebal_Val   Share_Val    Cash_Val  \\\n",
      "0  250.000000            0.00        0.000000  500.000000  500.000000   \n",
      "1  253.792987            3.15        3.792987  505.042987  505.042987   \n",
      "2  252.903193           -0.75       -0.889794  509.128441  509.128441   \n",
      "3  248.569479           -3.64       -4.333714  510.895327  510.895327   \n",
      "4  251.489691            2.41        2.920213  511.430760  511.430760   \n",
      "5  257.287034            4.84        5.797343  516.024672  516.024672   \n",
      "6  252.168002           -4.37       -5.119033  514.532802  514.532802   \n",
      "\n",
      "      Port_Val  \n",
      "0  1000.000000  \n",
      "1  1010.085974  \n",
      "2  1018.256881  \n",
      "3  1021.790655  \n",
      "4  1022.861519  \n",
      "5  1032.049343  \n",
      "6  1029.065604  \n",
      "thats all folks\n"
     ]
    }
   ],
   "source": [
    "# **********\n",
    "#\n",
    "# Main Program\n",
    "#1. Read specs for this run.\n",
    "#2. Check price_history file to see which prices are needed\n",
    "#3. Get those prices from DARqube.\n",
    "#4. Set up the results dataframe.\n",
    "#5. Run the backtester.\n",
    "#6. Calculate the stats for the run.\n",
    "#7. Update the run_log.\n",
    "#8. Plot the results.\n",
    "#\n",
    "# **********\n",
    "# **********\n",
    "# CONSTANTS\n",
    "# **********\n",
    "RUN_TYPE   = 'test'\n",
    "DAYS_BACK  = 10\n",
    "REBAL_FREQ = 'Daily'  # or EOW, EOM, EOQ, EOY\n",
    "TICKERS = ['XOM', 'AMZN']\n",
    "START_CASH = 1000.00\n",
    "CASH_PER_TICKER = 1000.0\n",
    "\n",
    "results_cols = ['Cash', 'Ticker_01_price', 'Ticker_01_shares', 'Ticker_01_vlaue', 'rebal'] # for each ticker\n",
    "run_log_cols = ['run_file_ID', 'run_date', 'start_date', 'end_date', 'rebal_freq', 'start_cash', \\\n",
    "                'tickers', 'periods', 'min_cash', 'max_drawdown', 'max_down_duration', 'Sharpe_ratio', \\\n",
    "                'ARR', 'cum_return', 'MAR']\n",
    "\n",
    "ticker_prices = pd.DataFrame(columns = ['time', 'Ticker', 'price'])\n",
    "\n",
    "# TODO  Add this functionality much later.\n",
    "if RUN_TYPE == 'backtest':\n",
    "    # every backtest is new, so initialize backtest.\n",
    "    # Get prices for selected tickers and date range.\n",
    "    # Get EOX dates based on backtest trade freq.\n",
    "    # Execute backtest with vector ops over date range, trade_freq, and tickers.\n",
    "    # Calculate performance stats.\n",
    "    # Log run in run_log. Log stats in run_log.\n",
    "    # Save backtest file and updated run_log.\n",
    "    # print charts of ticker values and cash on hand.\n",
    "    pass\n",
    "    \n",
    "if RUN_TYPE == 'port_trade':\n",
    "    # If port does not show up in run_log, then initialize this port in the run log and initialize the port_trade file.\n",
    "    # read port_trade file to set up trades.\n",
    "    # Check date and print recommended trades based on port_trade details\n",
    "    # Calculate port performance stats and generate plots.\n",
    "    pass\n",
    "\n",
    "TODAY = dt.datetime.today()\n",
    "print('TODAY = ', TODAY)\n",
    "\n",
    "end_date = TODAY - dt.timedelta(days = 1)\n",
    "print('end_date = ', end_date)\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "print('end_date_str = ', end_date_str)\n",
    "start_date = TODAY - dt.timedelta(days = DAYS_BACK)\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "print('start_date_str = ', start_date_str)\n",
    "\n",
    "#1. Get ticker prices.\n",
    "if RUN_TYPE == 'test':\n",
    "    all_ticker_prices = pd.read_csv('all_ticker_prices.csv')\n",
    "    all_ticker_prices.sort_values(by = ['date'], axis = 0, ascending = True, inplace = True)\n",
    "    print('when RUN_TYPE = tet, all_ticker_prices = ')\n",
    "    print(all_ticker_prices)\n",
    "    \n",
    "    #all_ticker_prices['date_str'] = all_ticker_prices['date'].dt.strftime('%Y-%m-%d')\n",
    "    start_date = all_ticker_prices.loc[0, 'date_str']\n",
    "    print('from all_ticker_prices, first date = ', start_date)\n",
    "    end_date = all_ticker_prices.loc[6, 'date_str']\n",
    "    print('from all_ticker_prices, last date = ', end_date)\n",
    "    print('Read all_ticker_prices.csv')\n",
    "else:\n",
    "    all_ticker_prices = GetStockPrices(start_date, end_date, TICKERS, DAR_key)\n",
    "    all_ticker_prices.to_csv('all_ticker_prices.csv')\n",
    "    print('GetStockPrices just ran.')                                                                                                \n",
    "\n",
    "#2.Get rebal dates for run. For testing, just set REBAL_FREQ = 'Daily'. \n",
    "run_prices = GetRebalData(all_ticker_prices, start_date_str, end_date_str, REBAL_FREQ)\n",
    "print('GetRebalData just ran.')\n",
    "\n",
    "#3. Call RebalDemon to execute the algo.\n",
    "run_report = RebalDemon(run_prices, TICKERS, start_date_str, end_date_str, START_CASH)\n",
    "print('Wow, RebalDemon just ran.')\n",
    "print(run_report)\n",
    "run_report.to_csv('run_report_test1.csv', index = False)\n",
    "    \n",
    "print('thats all folks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1954d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
